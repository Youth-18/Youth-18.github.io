---
layout:     post
title:      "论文理解-YOLOv3 "
date:       2018-8-16
author:     "Youth-18"
categories: 论文理解
tags:  论文理解
---  
  
### 一、Introduction  
不损失精度的前提下，速度又提升了。  
### 二、The Deal  
#### Bounding Box Prediction  
YOLOv3的box预测跟YOLOv2相同。  
$$
b_x = \sigma(t_x) + c_x \\
b_y = \sigma(t_y) + c_y \\
b_w = p_we^{t_w} \\
b_h = p_he^{t_h} \\
P_r(object)*IOU(b,object) = \sigma(t_o)
$$  
训练工程中我们使用平方和误差损失，我们预测的值是t0,我们的ground truth value是t1,那梯度就是t0-t1。groundtruth value可以很容易通过上面公式计算。  
YOLOv3使用逻辑回归来为每个bounding box预测objectness score。如果一个bounding box prior与ground truth object的重叠大于其他的bounding box prior，那么它的objectness score为1。我们为每个ground truth object分配一个bounding box prior，如果一个bounding box prior没有分配给object,那么将不会计算它的位置跟类别预测损失。  
#### Class Prediction  
每个box使用多标签分类来预测bounding box可能包含的类。舍弃掉softmax(默认每个box只包含一类，但实际上可能有多类，比如woman跟person,当object是woman时，这两个标签都是正确的)，使用独立的logistic分类，训练过程中使用二元交叉熵损失函数。  
#### Predictions Across Scales   
YOLOv3提取特征部分类似FPN，它从**3个不同的尺度**来预测box，又添加了几层卷积网络来构成基础的特征提取器。最后会**预测3-d tensor enconding，包括bounding box,objectness,class predictions**。比如在COCO中，我们每个尺度预测3个boxes，所以这个tensor就是$N*N*[3*(4+1+80)]$，3：3个boxes，4：4个bounding box offset，1：1个objectness(置信度)，80:80个类预测。  
我们从先前的2个层中提取特征图将其上采样为原来的2倍。然后将将其与更前层的特征图融合。这样可以从上采样特征中得到更有意义的语义分割信息，从更早的特征图中得到细粒度信息。我们添加了更多卷积层来处理这个融合的特征图，然后预测相同的tensor，尽管尺寸两倍大。  
还是使用k-means来聚类9个boxes。  
#### Feature Extractor  
Darknet-53  
![](/blog_image/YOLOv3_0.jpeg)   
#### Training  
训练过程中没有hard negative mining，使用了multi-scale training,data augmentation,BN。

