---
layout:     post
title:      "论文理解-YOLOv1 "
date:       2018-8-16
author:     "Youth-18"
categories: 论文理解
tags:  论文理解
---   

参考：https://blog.csdn.net/hrsstudy/article/details/70305791
![](/blog_image/YOLO0.jpeg)
基于回归的方式来检测目标。  
### 一、Unified Detection  
我们的网络把输入图像分成S×S个格，如果物体的中心落在格中，那这个格将负责检测这个物体。  
每个格预测B个bounding boxes以及这些boxes的confidence scores。这些confidence scores反映了boxes中是否含有含有物体以及boxes坐标的准确度。公式如下：  $confidence=Pr(Object)*IOU^{truth}_{pred}$  
即，当栅格中有物体，即boxes中含有物体时，Pr(Object)=1,所以confidence score就等于predicted box与groundtruth box的IOU。当栅格中没有物体时，confidence score就等于0。   
每个bounding box 包含5个预测值：x,y,w,h,confidence。坐标(x,y)代表了box中心与栅格边界的相对值。预测的w,h是box相对于整幅图像的width跟height。confidence代表predicted box与groundtruth box的IOU。
每个栅格还会预测C个条件类别概率(conditional class probabilities)的可能性，即$Pr(Calss_i|Object)$。即当栅格中含有物体的条件下，它属于某个类的可能性。我们只预测每个栅格中一系列类的可能性，而不管boxes B的数量。  
在测试阶段，我们将conditional class probabilities跟每个box的confidence相乘。  
$$
Pr(Class_i|Object)*Pr(Object)*IOU^{truth}_{pred} = Pr(Class_i)*IOU^{truth}_{pred}
$$  
这个给了我们每个box具体类的confidence scores。这些分数既表示这个类出现在这个box的可能性，又体现了predicted box与object的拟合程度(即box与object的重叠度，即groundtruth box与predicted box的IOU)。  
**每张图像分成S\*S个grid cell,每个cell预测B个bounding boxes(x,y,w,h)，以及这些boxes的confidence，以及C个类的probabilities。也可以这样理解，S\*S个cell,每个cell预测B个boxes，每个boxes含有5个预测值(x, y, w, h, confidence)，每个cell还预测C个类的Probabilities。所以每张图像可encode成$S\*S\*(B*5+C)$维的tensor。**  
### 二、Network Design    
网络的卷积层用来提取图像的特征，全连接层用来预测输出坐标跟类的概率值。  
我们的网络结构借鉴了GoogLeNet用来图像分类。我们的网络有24个卷积层跟2个全连接层。但是并没有用GoogLeNet中的inception modules，而是用了1\*1来减小前面层的特征空间，后面是3\*3卷积层。  
我们训练的Fast YOLO能够更快的检测物体，Fast YOLO使用了更少的卷积层(9个)以及更少的filter，除了网络尺寸不一样，训练跟测试参数都跟YOLO是相同的。![](/blog_image/YOLO1.jpeg)  
### 三、Training  
我们在ImageNet 1000-class数据集上预训练我们的卷积层，我们先使用图像中所示的前二十个卷积层，后跟一个average pooling层，一个全连接层。  
我们用这个模型来检测，同时添加了随机初始化权重的四个卷积层跟两个全连接层。检测需要细粒度的视觉特征信息(fine-grained visual information)，所以我们把输入图像的分辨率从224\*224调整为448\*448。同时在第一个全连接层后加入一个ratio=0.5的Dropout层，防止过拟合。同时做了数据增强。  
我们把预测的bounding boxes的(x,y,w,h)全都归一化为0-1之间。并且使用leaky RELU作为线性激活函数:
$$
\phi(x)=\begin{cases} x, & \text {if $x$ > 0} \\ 0.1x, & \text{otherwise} \end{cases}
$$
我们在我们的模型上优化了求和平方误差，我们使用求和平方误差的作用是因为它好优化，但是，与我们最大化平均精度的目的不相符。将8维的localization error(一个cell中2个box的坐标(x,y,w,h))与20维的calssification error(20个类)一样重要是不合理的。并且大多数栅格中并不包含物体，这就使得confidence scores为0，使其比包含物体的栅格来说对梯度的贡献更大。这会导致模型不稳定，引起在训练早期发散。
![](/blog_image/YOLO2.png)  
**更重视8维的坐标预测，给这些损失前面赋予更大的loss weight, 记为 λcoord ,在pascal VOC训练中取5。（上图蓝色框）**   
**对没有object的bbox的confidence loss，赋予小的loss weight，记为 λnoobj ，在pascal VOC训练中取0.5。（上图橙色框）**   
**有object的bbox的confidence loss (上图红色框) 和类别的loss （上图紫色框）的loss weight正常取1。**  
同时求和平方损失对于大、小boxes的权重是一样的，但是小boxes的偏移明显比大boxes的偏移对误差的影响更重要(小boxes偏移一点对IOU的影响比大boxes更大)。**所以我们用width跟height的平方根来替代直接使用width跟height。**$$  $$  
在YOLO中每个栅格会预测很多bounding boxes，**在训练的时候，我们想用一个bounding box作为predictor来预测object，我们将与groundtruth box的IOU最大的一个bounding box作为这个predictor。**这样每个predictor在预测确定的尺寸、长宽比、物体的类别和召回率方面有更好的表现。  
### 四、Limitations of YOLO  
YOLO对于小物体的检测并不理想，因为可能多个小物体落在一个栅格，而一个栅格只能预测一个物体。  
我们的模型是从数据中预测bounding boxes，所以对于新的或者不同的寻常的长宽比或配置泛化能力较差。我们的模型使用粗糙的特征来预测bounding boxes，因此使用了输入图像的多个下采样。  
最后，对于小bounding box的偏移对loss影响应该更大这件事我们并没有完全解决。我们主要的错误来自incorrect localizations。
