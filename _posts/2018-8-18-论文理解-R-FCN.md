---
layout:     post
title:      "论文理解-R-FCN"
date:       2018-8-18
author:     "Youth-18"
categories: 论文理解
tags:  论文理解
---  

参考：[R-FCN](https://blog.csdn.net/WZZ18191171661/article/details/79481135)
#### 一、理解两个概念  
1.**translation-invariance**:在分类任务中，不管目标在图片的哪个位置，都能分类正确，对目标所在的位置不敏感，这就是所谓的translation-invariance。  
2.**translation-variance**:在目标检测任务中，需要正确检测出目标在图片的哪个位置，对目标所在的位置敏感，这就是所谓的translation-variance。  
#### 二、R-FCN采用的方法  
采用的是two-stage目标检测方法，网络的大体架构如下图：  
![](/blog_image/R-FCN0.jpg)  
在R-FCN中，所有的可学习权重都是卷积的并且在整张图上进行计算。整个流程如下：  
* 输入一张图片，对图片进行预处理  
* 将预处理后的图片送入预训练好的分类网络中  
* 在预训练网络的最后一个卷积层获得的feature map上存在三个分支，第一个分支就是在feature map上进行RPN操作，获得ROI；第二个分支就是在该feature map上获得一个$k^2(C+1)$维的位置敏感分数图，用来分类；第三个分支就是在该feature map上获得一个$k^2\*4$的位置敏感分数图，用来进行回归。
* 然后将RPN产生的ROI映射到这两个位置敏感分数图上，然后进行位置敏感的ROI池化操作。  

**Position-Sensitive Score Map(位置敏感分数图)**  

预训练网络最后的卷积层会为**每个类别**产生**一组**个数为$k^2$的位置敏感分数图，因此输出的通道数为$k^2(C+1)$，C个目标类别跟一个背景类别，即位置敏感分数图是一个通道数为$k^2(C+1)$的**卷积层**。每个类别对应着$k^2$个位置敏感分数图，**每个位置敏感分数图**负责预测这个类别的**某个位置**。当确定这个ROI所包含物体的类别时，将这个ROI分成 $k\*k$ 个小格，分别对应着$k\*k$个位置，比如当计算这个ROI中包含的是不是人时，$k\*k$个小格分别代表人的$k^2$个位置，比如top-center代表人的头部，bottom-center代表人的脚，**每个**小格对应人的**一个**位置敏感分数图，top-center这个小格对应的位置敏感分数图会来预测这个位置是否是头部。  

**Position-Sensitive Rol Pooling**  

![](/blog_image/R-FCN1.jpg)  
根据上图可以清晰的理解这个pooling过程，每种颜色表示负责预测的一种位置，比如黄色负责预测所有$(C+1)$个种类的top-left，pooling过程就是将黄色map中ROI所对应的top-left区域进行平均池化，每种类别对应的$k^2$个maps池化后变为$k*k$的map，一共有$(C+1)$个类别所以池化层的大小为$k\*k\*(C+1)$。这是对于分类，对于回归来说，大体相似，只不过将$(C+1)$个类别换成4个坐标。然后**分类**过程中进行vote(将每个类别对应的$k\*k$个响应值相加得到这个类别的分数)操作，得到$(C+1)\*1\*1$维的卷积，然后接softmax函数，来确定最后的类别。  

**预测物体类别的直观解释**  

![](/blog_image/R-FCN2.jpg)  
![](/blog_image/R-FCN3.jpg)  
当ROI中包含物体时，每个格所对应的响应值都会很大(值越大越白),这种能力是由训练过程中得到的。在训练过程中，每个ROI要不属于GT要不属于背景，与GT具有最大IOU的ROI其得分为1，然后其他大于阈值(此处为0.5)其得分按照IOU来确定，然后依据损失函数来回归，这就使其**坐标预测**越来越准确。大于阈值的为正样本，其他的背景。这就是每个ROI都有一个标签，这样就可以用监督的方式来训练，使其**类别预测**越来越准确。  

**损失函数**  

跟其他两阶段的目标检测框架一样，损失函数包括分类损失与回归损失，分类损失使用的是cross-entropy loss。loss公式如下：  
$$
L(s,t_{x,y,w,h}) = L_{cls}(s_{c^*}) + \lambda[c^* > 0]L_{reg}(t,t^*)
$$  
$c^*$代表GT label(=0表示为背景)；    
$L_{cls}(s_{c^*})=-log(s_{c^*})$为分类的cross-entropy loss;   

$L_{reg}$为bounding box regression loss；   
$t^*$代表GT box。
